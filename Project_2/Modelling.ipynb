{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_states = ['35801','99501','85001','72201','90001','80201','06101','19901','20001','33124','30301','96801','83254','60601','46201','52801','67201','41701','70112','04032','21201','02101','49036','55801','39530','63101','89501','03217','07039','87500','10001','27565','44101','74101','97201','15201','02840','29020','37201','78701','84321','24517','98004','53201']\n",
    "def get_data(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(file))\n",
    "    return pd.concat(dfs)\n",
    "list_files = []\n",
    "#for i in range(0,50000,2000):\n",
    "    #string = 'cars'+str(i)+'_'+str(i+2000)\n",
    "    #list_files.append(string) \n",
    "#for i in range(50000,100000,5000):\n",
    "    #string = 'cars'+str(i)+'_'+str(i+5000)\n",
    "    #list_files.append(string)\n",
    "for i in list_states:\n",
    "    string = 'cars0_1500_'+i\n",
    "    list_files.append(string)\n",
    "    string1 = 'cars1500_3000_'+i\n",
    "    list_files.append(string1)\n",
    "print(list_files)\n",
    "df = get_data(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Model.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drivetrain(dataset):\n",
    "    dataset['Drivetrain'].replace(['4X4','4x4','4MATIC','AWD','All Wheel Drive', 'All-wheel Drive','awd', \n",
    "                                   'Four Wheel Drive', 'quattro', 'AWD/4WD', 'Automatic Full-Time All-Wheel Drive',\n",
    "                                   '4 Wheel Drive', '4MATIC&reg', 'Full-Time All-Wheel Drive', 'quattro all-wheel drive', 'AllWheelDrive', '4wd', 'FourWheelDrive', 'All-Wheel', '\"All Wheel Drive\"', 'AWD: All Wheel Drive', 'ALL4', 'FOUR-WHEEL DRIVE', 'ALL-WHEEL DRIVE', '4x4/4-wheel drive', 'Four-Wheel Drive with Locking and Limited-Slip Differential'], \n",
    "                                  value = '4WD', inplace = True)\n",
    "    dataset['Drivetrain'].replace(['Front Wheel Drive', '2WD/FWD', 'Front Wheel Drive', 'Front-Wheel Drive', \n",
    "                                   'Front-wheel Drive', 'FrontTrak', 'FrontWheelDrive', 'FRONT WHEEL','F',\n",
    "                                   'Front wheel drive', '4X2','4x2', '2 Wheel Drive', 'Drivetrain, front-wheel drive (FWD models only.)', '\"Front Wheel Drive\"', 'Front-Whee', 'fwd', 'Drivetrain, front-wheel drive','FWD: Front Wheel Drive', 'Front-Wheel Drive with Limited-Slip Differential', 'FRONT WHEEL DRIVE']\n",
    "                                  , value = 'FWD', inplace = True)\n",
    "    dataset['Drivetrain'].replace(['2WD', 'Rear Wheel Drive', 'RearWheelDrive', 'Rear-wheel Drive', 'REAR WHEEL', 'Rear-Wheel Drive', 'Rear wheel drive', 'Rear-Wheel', 'rwd', 'Drivetrain, rear-wheel drive','RWD: Rear Wheel Drive', 'REAR WHEEL DRIVE', 'Rear-Wheel Drive with Limited-Slip Differential'], value = 'RWD', inplace = True)\n",
    "    \n",
    "    mask = (dataset['Drivetrain'] == '4WD') | (dataset['Drivetrain'] == 'FWD')|(dataset['Drivetrain'] == 'RWD')\n",
    "    dataset['Drivetrain'].where(mask, other = np.NaN, inplace = True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanexcolors(dataset):\n",
    "    dataset['Exterior Color'] = dataset['Exterior Color'].str.lower()\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*white.*',r'.*pearl.*',r'.*bianco.*', r'.*powder.*', r'.*ice.*'],\n",
    "                                      value = 'White', inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*black.*',r'.*ebony.*',r'.*obsidian.*',r'.*nero.*', r'.*blac k.*'], \n",
    "                                  value = 'Black',inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*blue.*',r'.*blu.*', r'.*sea.*', r'.*sapphire.*'], \n",
    "                                      value = 'Blue', inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*red.*',r'.*fire.*', r'.*rosso.*', r'.*burgundy.*', r'.*ruby.*'], \n",
    "                                      value = 'Red', inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*gray.*',r'.*grey.*', r'.*slate.*',r'.*tungsten.*',\n",
    "                                                   r'.*granite.*', r'.*graphite.*',r'.*ash.*',r'.*charcoal.*', \n",
    "                                               r'.*grigio.*',r'.*magnetic.*', r'.*taupe.*', r'.*stone.*',r'.*shale.*',\n",
    "                                               r'.*pewter.*',r'.*ceramic.*',r'.*alloy.*', 'light neutral',r'.*oyster.*'], \n",
    "                                      value = 'Grey', inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*silver.*', r'.*metallic.*', r'.*iron.*',r'.*platinum.*',r'.*billet.*',\n",
    "                                               r'.*tectonic.*',r'.*steel.*', r'.*titanium.*'], \n",
    "                                      value = 'Silver', inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*brown.*', r'.*maroon.*', r'.*coffee.*', r'.*cocoa.*',r'.*toffee.*', \n",
    "                                                   r'.*bronze.*','titanium flash mica', r'.*cappuccino.*', r'.*cuoio.*',\n",
    "                                               r'.*cognac.*',r'.*mocha.*',r'.*saddle.*'], value = 'Brown', inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*green.*',r'.*alien.*',r'.*jade.*'], value = 'Green', \n",
    "                                      inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*yellow.*',r'.*celvet.*'], value = 'Yellow', \n",
    "                                      inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*gold.*', r'.*champagne.*'], value = 'Gold', \n",
    "                                      inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*orange.*',r'.*sunset.*',r'.*copper.*',r'.*vitamin.*',r'.*lava.*'], \n",
    "                                  value = 'Orange', inplace = True, regex = True)\n",
    "    dataset['Exterior Color'].replace(to_replace =[r'.*beige.*',r'.*tan.*',r'.*sand.*',r'.*camel.*', r'.*almond.*', \n",
    "                                               r'.*bisque.*', r'.*cream.*', r'.*cashmere.*', r'.*wheat.*',r'.*blond.*',\n",
    "                                               r'.*parchment.*'], value = 'Beige', inplace = True, regex = True)\n",
    "    \n",
    "    #Eliminate all colours which are not (White, Black, Silver, Grey, Red, Blue, Green, Brown)\n",
    "    mask = (dataset['Exterior Color'] == 'White') | (dataset['Exterior Color'] == 'Black')|(dataset['Exterior Color'] == 'Silver')| \\\n",
    "    (dataset['Exterior Color'] == 'Grey')|\\\n",
    "    (dataset['Exterior Color'] == 'Red')|(dataset['Exterior Color'] == 'Blue')|(dataset['Exterior Color'] == 'Brown')\\\n",
    "    |(dataset['Exterior Color'] == 'Green')\n",
    "    dataset['Exterior Color'].where(mask, other = 'Exotic', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanincolors(dataset):\n",
    "    dataset['Interior Color'] = dataset['Interior Color'].str.lower()\n",
    "    dataset['Interior Color'].replace(to_replace =[r'.*black.*',r'.*ebony.*',r'.*obsidian.*',r'.*nero.*', r'.*blac k.*', r'.*charcoal.*'], \n",
    "                                  value = 'Black',inplace = True, regex = True)\n",
    "\n",
    "    dataset['Interior Color'].where((dataset['Interior Color'] == 'Black'), other = 'Non-black', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitmodel(dataset):\n",
    "    df = dataset['Model'].str.split(pat = ' ', expand = True)\n",
    "    #model = pd.concat([df.iloc[:,1],df.iloc[:,2]])\n",
    "    #print(model)\n",
    "    dataset.insert(loc = 1, column = 'Carmaker', value = df.iloc[:,0])\n",
    "    #dataset['Model'] = model\n",
    "    dataset['Model'] = df[1].str.cat(df[2], sep =\" \")\n",
    "    \n",
    "    #Categorize Models\n",
    "    model_counts = dataset.Model.value_counts()\n",
    "    other_models = list(model_counts[model_counts < 50].index)\n",
    "    dataset.loc[dataset['Model'].isin(other_models),'Model'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantransmission(dataset):\n",
    "    \"\"\"Categorizes transmission data into Automatic, Manual, CVT and NaN\"\"\"\n",
    "    dataset['Transmission'] = dataset['Transmission'].str.lower()\n",
    "    dataset['Transmission'].replace(to_replace =[r'.*auto.*', r'.*a/t.*', r'.*pdk.*', r'.*tiptronic.*',r'.*dual.*',\n",
    "                                                 r'.*8.*','7-speed',r'.*select.*', r'.*single.*', r'.*Automatic.*', r'.*speedshift.*', '10 speed', 'All-Wheel', '6a'], \n",
    "                                    value = 'Automatic',inplace = True, regex = True)\n",
    "    dataset['Transmission'].replace(to_replace =['a'],value = 'Automatic',inplace = True, regex = False)\n",
    "    dataset['Transmission'].replace(to_replace =['m'],value = 'Automatic',inplace = True, regex = False)\n",
    "    dataset['Transmission'].replace(to_replace =[r'.*manual.*', '6-speed',r'.*5.*', r'.*Manual.*', '6 speed', '4 speed', '4a w/ od' ], \n",
    "                                  value = 'Manual',inplace = True, regex = True)\n",
    "    dataset['Transmission'].replace(to_replace =[r'.*cvt.*', r'.*variable.*'], \n",
    "                                  value = 'CVT',inplace = True, regex = True)\n",
    "    \n",
    "    mask = (dataset['Transmission'] == 'Automatic') | (dataset['Transmission'] == 'Manual')|(dataset['Transmission'] == 'CVT')\n",
    "    dataset['Transmission'].where(mask, other = np.NaN, inplace = True)\n",
    "\n",
    "\n",
    "    #dataset['Transmission'].replace(to_replace =['not specified', 'unspecified', 'c', 'unknown/ other', '72400401623033', 'dfl'], alue = np.NaN ,inplace = True, regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanengine(dataset):\n",
    "    \"\"\"Categorizes dataset in 4-,6-,8-cylinders and Electro\"\"\"\n",
    "    dataset['Engine'] = dataset['Engine'].str.lower()\n",
    "    dataset['Engine'].replace(to_replace =[r'.*v4.*', r'.*4 cylinder.*', r'.*4-v,*', r'.*4-cylinder.*', r'.*2.4.*', \n",
    "                                           r'.*4-cyl.*', r'.*4 cyl.*', r'.*i4.*', r'.*i-4.*', r'.*h4.*', r'.*h-4.*', \n",
    "                                           r'.*1..*', r'.*2.0.*'], value = '4',inplace = True, regex = True)\n",
    "    dataset['Engine'].replace(to_replace =[r'.*v6.*', r'.*6 cylinder.*', r'.*v-6.*', r'.*6-cylinder.*', r'.*h6.*', \n",
    "                                           r'.*h-6.*', r'.*i6.*', r'.*i-6.*', r'.*3..*'], \n",
    "                                  value = '6',inplace = True, regex = True)\n",
    "    dataset['Engine'].replace(to_replace =[r'.*v8.*', r'.*8 cylinder.*', r'.*v-8.*', r'.*8-cylinder.*', r'.*8 cyl.*', \n",
    "                                           r'.*8-cyl.*', r'.*5..*'], \n",
    "                                  value = '8',inplace = True, regex = True)\n",
    "    dataset['Engine'].replace(to_replace =[r'.*v10.*', r'.*10 cylinder.*', r'.*v-10.*', r'.*10-cylinder.*'], \n",
    "                                  value = '10',inplace = True, regex = True)\n",
    "    dataset['Engine'].replace(to_replace =[r'.*v12.*', r'.*12 cylinder.*', r'.*v-12.*', r'.*12-cylinder.*', \n",
    "                                           r'.*w12.*'], value = '12',inplace = True, regex = True)\n",
    "    dataset['Engine'].replace(to_replace =[r'.*electro.*', r'.*electric.*'], \n",
    "                                  value = 'Electric',inplace = True, regex = True)\n",
    "    #Create new cylinder columns and remove engine column\n",
    "    dataset.insert(loc = 14, column = 'Cylinders', value = dataset['Engine'])\n",
    "    \n",
    "    #Replace unecessary classifications\n",
    "    mask = (dataset['Cylinders'] == '4') | (dataset['Cylinders'] == '6')|(dataset['Cylinders'] == '8')|(dataset['Cylinders'] == 'Electric')\n",
    "    dataset['Cylinders'].where(mask, other = np.NaN, inplace = True)\n",
    "    \n",
    "    #Drop Engine Column\n",
    "    dataset = dataset.drop(columns = 'Engine', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stateclassification(dataset):\n",
    "    NE = ['PA', 'NY', 'NJ', 'RI', 'CT', 'MA', 'NH', 'VT', 'ME']\n",
    "    S = ['MD', 'VA', 'DE', 'WV', 'NC', 'SC', 'GA', 'AL', 'MS', 'TN', 'KY', 'LA', 'TX', 'OK', 'AR', 'FL', 'AK']\n",
    "    MW = ['ND', 'SD','MN', 'IA', 'NE', 'KS', 'MO', 'WI', 'MI', 'IL', 'IN', 'OH' ]\n",
    "    W = ['WA','OR', 'CA','MT', 'ID', 'NV', 'WY', 'UT', 'CO', 'AZ', 'NM' , 'HI']\n",
    "    dataset['State'].replace(to_replace = NE, \n",
    "                                  value = 'Northeast',inplace = True, regex = True)\n",
    "    dataset['State'].replace(to_replace = S, \n",
    "                                  value = 'South',inplace = True, regex = True)\n",
    "    dataset['State'].replace(to_replace = MW, \n",
    "                                  value = 'Midwest',inplace = True, regex = True)\n",
    "    dataset['State'].replace(to_replace = W, \n",
    "                                  value = 'West',inplace = True, regex = True)\n",
    "    #Drop Zipcode column\n",
    "    dataset = dataset.drop(columns = 'Zipcode',inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandeal(dataset):\n",
    "    dataset['Deal'].replace(np.NaN, '0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhotbadge(dataset):\n",
    "    dataset['Hot Badge'].replace(np.NaN, '0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanfuel(dataset):\n",
    "    dataset['Fuel'].replace(to_replace = ['Compressed Natural Gas', 'Unknown'], value = np.NaN, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanrating(dataset):\n",
    "    dataset['Seller Rating'] = dataset['Seller Rating'].round(decimals = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanreviews(dataset):\n",
    "    value_list = []\n",
    "    for value in dataset['Seller Reviews']:\n",
    "        if value <10:\n",
    "            value_list.append(1)\n",
    "        elif value <100:\n",
    "            value_list.append(round(value, ndigits = -1))\n",
    "        elif value < 1000:\n",
    "            value_list.append(round(value, ndigits = -2))\n",
    "        elif value < 10000:\n",
    "            value_list.append(round(value, ndigits = -3))\n",
    "        else:\n",
    "            value_list.append(round(value, ndigits = -4))\n",
    "    \n",
    "    dataset['Seller Reviews'] = value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanmileage(dataset):\n",
    "    dataset['Mileage'].replace(to_replace='Not provided', value = np.NaN, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "drivetrain(df2)\n",
    "cleanexcolors(df2)\n",
    "cleanincolors(df2)\n",
    "splitmodel(df2)\n",
    "cleantransmission(df2)\n",
    "cleanengine(df2)\n",
    "stateclassification(df2)\n",
    "cleandeal(df2)\n",
    "cleanhotbadge(df2)\n",
    "cleanfuel(df2)\n",
    "cleanrating(df2)\n",
    "cleanreviews(df2)\n",
    "cleanmileage(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Drivetrain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df2['Cylinders'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df['Transmission'].value_counts())\n",
    "(df2.groupby(['Model']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Model.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2.drop(index = 808)\n",
    "df3 = df2.dropna().reset_index()\n",
    "df3 = df3.drop(['Link', 'index', 'VIN'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Price'] = df3['Price'].str.replace('$','')\n",
    "df3['Price'] = df3['Price'].str.replace(',','')\n",
    "df3['Price'] = df3['Price'].astype(int64)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.sort_values(['Price'], ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Mileage to integer\n",
    "df3['Mileage'] = df3['Mileage'].str.replace(',','')\n",
    "df3['Mileage'] = df3['Mileage'].astype(int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df3['Year'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3['Model'].value_counts())\n",
    "model_counts = df3.Model.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4 = df3[df3['Carmaker'] != 'Ferrari']\n",
    "df4= df3[df3['Price'] < 100000]\n",
    "df4 = df4[df4['Carmaker'] != 'Aston']\n",
    "#df4 = df4[df4['Carmaker'] != 'Porsche']\n",
    "#df4 = df3.copy()\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Year']=df4['Year'].astype(int64)\n",
    "df4['Mileage']=df4['Mileage'].astype(float64)\n",
    "df4 = df4[df4.Mileage < 300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create baseline by removing non-numerical values\n",
    "numbers = df4.select_dtypes(exclude=['object']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numbers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(numbers, plot_kws=dict(alpha=.5, edgecolor='none'), height = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exponential relationship between year and price\n",
    "#Exponential relationshgip between Seller Reviews and Year\n",
    "#Exponential relationshgip between Seller Rating and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Baseline\n",
    "X = numbers.loc[:,['Year', 'Seller Reviews', 'Seller Rating', 'Mileage']]\n",
    "y = numbers['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_validate(X, y):\n",
    "    '''\n",
    "    For a set of features and target X, y, perform a 80/20 train/val split, \n",
    "    fit and validate a linear regression model, and report results\n",
    "    '''\n",
    "    \n",
    "    # perform train/val split\n",
    "    X_train, X_val, y_train, y_val = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # fit linear regression to training data\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # score fit model on validation data\n",
    "    val_score = lr_model.score(X_val, y_val)\n",
    "    \n",
    "    # report results\n",
    "    print('\\nValidation R^2 score was:', val_score)\n",
    "    print('Feature coefficient results: \\n')\n",
    "    for feature, coef in zip(X.columns, lr_model.coef_):\n",
    "        print(feature, ':', f'{coef:.2f}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_validate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Year^2'] = X['Year']**2\n",
    "split_and_validate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Mileage^2'] = numbers['Mileage']**(2)\n",
    "split_and_validate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop(labels = 'Mileage', inplace = True, axis = 1)\n",
    "#split_and_validate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['SellerReviews^-2'] = X['Seller Reviews']**(-2)\n",
    "#split_and_validate(X,y)\n",
    "#Worsened score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['SellerRating^2'] = X['Seller Rating']**2\n",
    "#split_and_validate(X,y)\n",
    "#Worsened Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['log_Year'] = np.log(X['Year'])\n",
    "#split_and_validate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['SellerReviews_SellerRating'] = X['Seller Reviews']*X['Seller Rating']\n",
    "#split_and_validate(X,y)\n",
    "#Worsened Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['Mileage_Year'] = X['Mileage']*X['Year']\n",
    "#split_and_validate(X,y)\n",
    "#Worsened score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['Mileage^-2'] = X['Mileage']**(-2)\n",
    "#split_and_validate(pd.get_dummies(X, drop_first=True), y)\n",
    "#Worsened score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['SellerRating^2'] = df3['Seller Rating']**2\n",
    "#split_and_validate(pd.get_dummies(X, drop_first=True), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worsened the Model\n",
    "X['log_SellerReviews'] = np.log(X['Seller Reviews'])\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['SellerReviews^3'] = X['Seller Reviews'] **3\n",
    "#split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Carmaker'] = df3['Carmaker']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Model'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Model'] = df3['Model']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Deal'] = df3['Deal']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)\n",
    "#Didn't change much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Hot Badge'] = df3['Hot Badge']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)\n",
    "#Changed a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Fuel'] = df3['Fuel']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Exterior Color'] = df3['Exterior Color']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Interior Color'] = df3['Interior Color']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Drivetrain'] = df3['Drivetrain']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Transmission'] = df3['Transmission']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)\n",
    "#No change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Cylinders'] = df3['Cylinders']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X['State'] = df3['State']\n",
    "split_and_validate(pd.get_dummies(X, drop_first=True), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X)\n",
    "X, y = X_dummies, df4['Price']\n",
    "\n",
    "# hold out 20% of the data for final testing\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting up data into train and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 3 models we're choosing from:\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.transform(X_val.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "lm_reg = RidgeCV(store_cv_values = True)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "#poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "#X_train_poly = poly.fit_transform(X_train.values)\n",
    "#X_val_poly = poly.transform(X_val.values)\n",
    "#X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "#lm_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear Regression val R^2: {lm.score(X_val, y_val):.3f}')\n",
    "\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge Regression val R^2: {lm_reg.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "#lm_poly.fit(X_train_poly, y_train)\n",
    "#print(f'Degree 2 polynomial regression val R^2: {lm_poly.score(X_val_poly, y_val):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha value\n",
    "#lm_reg.cv_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing against test data\n",
    "lm.fit(X,y)\n",
    "print(f'Linear Regression test R^2: {lm.score(X_test, y_test):.3f}')\n",
    "\n",
    "X_reg = scaler.fit_transform(X.values)\n",
    "lm_reg.fit(X_reg,y)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')\n",
    "\n",
    "#X_poly = poly.fit_transform(X.values)\n",
    "#lm_poly.fit(X_poly,y)\n",
    "#print(f'Degree 2 polynomial Regression test R^2: {lm_poly.score(X_test_poly, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation using Ridge and Lasso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_dummies, df4['Price']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10) #hold out 20% of the data for final testing\n",
    "\n",
    "#this helps with the way kf will generate indices below\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_dummies, df4['Price']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10) \n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=43)\n",
    "\n",
    "#Finding optimal alpha value for Ridge and Lasso\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X.values)\n",
    "\n",
    "## Scale the Predictors on both the train and test set\n",
    "X_tr=scaler.transform(X.values)\n",
    "X_te=scaler.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "\n",
    "alphavec = 10**np.linspace(-2,2,400)\n",
    "\n",
    "lasso_model = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso_model.fit(X_tr, y)\n",
    "\n",
    "lm_reg = RidgeCV(alphas = alphavec, cv= 5)\n",
    "lm_reg.fit(X_tr, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lasso: '+str(lasso_model.alpha_))\n",
    "print('Ridge: '+str(lm_reg.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(list(zip(X.columns, lasso_model.coef_)))\n",
    "coef.sort_values(by = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(zip(X.columns, lm_reg.coef_))\n",
    "coef = list(zip(X.columns, lasso_model.coef_))\n",
    "#coef.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the new model\n",
    "test_set_pred = lasso_model.predict(X_te)\n",
    "\n",
    "test_set_pred_ridge = lm_reg.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X.columns, lasso_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error (MAE)\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_true)) \n",
    "\n",
    "mae(y_test, test_set_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the MAE and R^2 on the test set using this model\n",
    "print('Lasso: '+str(mae(y_test, test_set_pred)))\n",
    "print('Ridge: '+str(mae(y_test, test_set_pred_ridge)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test, test_set_pred))\n",
    "print(r2_score(y_test, test_set_pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the residuals\n",
    "residuals = (test_set_pred_ridge - y_test)\n",
    "df4['residuals'] = residuals\n",
    "positive_residuals= df4['residuals'][df4['residuals'] > 30000]\n",
    "negative_residuals = df4['residuals'][df4['residuals'] < -30000]\n",
    "plt.scatter(df4['Price'], df4['residuals'])\n",
    "df4.sort_values(by = 'residuals', ascending = True).head(50)\n",
    "#df.iloc[2246,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Q-Q plot\n",
    "plt.figure(figsize = (20,5))\n",
    "plt.subplot(1, 3, 3)\n",
    "#Generates a probability plot of sample data against the quantiles of a \n",
    "# specified theoretical distribution \n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "\n",
    "# Plot fit \n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(test_set_pred,y_test)\n",
    "plt.plot(y_test, y_test, color='blue',linewidth=1)\n",
    "plt.title(\"Regression fit\")\n",
    "plt.xlabel(\"Predicted Price\")\n",
    "plt.ylabel(\"Actual Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['Price']=='$53,990'].sort_values(by = 'Price', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[df4.Price > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['res'] = abs(m.predict(df[['x1', 'x2']])-df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mileage = df4.Mileage\n",
    "price = df4.Price\n",
    "plt.scatter(mileage, price)\n",
    "plt.xlabel('Mileage')\n",
    "plt.ylabel('Price')\n",
    "plt.xticks(ticks = [0,50000,100000,150000,200000,250000,300000])\n",
    "plt.yticks(ticks = [0,20000,40000,60000,80000,100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2 = X['Year^2']\n",
    "plt.hist(year_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silverado = df4[df4['Model'] == 'Silverado 1500']\n",
    "mileage = df_silverado['Mileage']\n",
    "price = df_silverado['Price']\n",
    "plt.scatter(mileage,price)\n",
    "plt.xlabel('Mileage')\n",
    "plt.ylabel('Price')\n",
    "plt.xticks(ticks = [0,50000,100000,150000,200000,250000,300000])\n",
    "plt.yticks(ticks = [0,20000,40000,60000,80000,100000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Price'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
